{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "import string, re, json\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.mongodb.input.uri\", \"mongodb://192.168.1.27/TwitterSentimentAnalysis.LabeledDataset?retryWrites=true\") \\\n",
    "        .config(\"spark.mongodb.output.uri\", \"mongodb://192.168.1.27/TwitterSentimentAnalysis.LabeledDataset?retryWrites=true\") \\\n",
    "        .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TweetLabeled = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove whitespace\n",
    "def remove_all_space(astring):\n",
    "  return \" \".join(astring.split())\n",
    "\n",
    "# clean the text \n",
    "def remove_features(data_str):\n",
    "    # compile regex\n",
    "    url_re = re.compile('https?://(www.)?\\w+\\.\\w+(/\\w+)*/?')\n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    num_re = re.compile('(\\\\d+)')\n",
    "    alpha_num_re = re.compile(\"^[a-z0-9_.]+$\")\n",
    "    # convert to lowercase\n",
    "    data_str = data_str.lower()\n",
    "    # remove hyperlinks\n",
    "    data_str = url_re.sub(' ', data_str)\n",
    "    # remove puncuation\n",
    "    data_str = punc_re.sub(' ', data_str)\n",
    "    # remove numeric 'words'\n",
    "    data_str = num_re.sub(' ', data_str)\n",
    "    # remove non a-z 0-9 characters and words shorter than 3 characters\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    for word in data_str.split():\n",
    "        if list_pos == 0:\n",
    "            if alpha_num_re.match(word) and len(word) > 2:\n",
    "                cleaned_str = word\n",
    "            else:\n",
    "                cleaned_str = ' '\n",
    "        else:\n",
    "            if alpha_num_re.match(word) and len(word) > 2:\n",
    "                cleaned_str = cleaned_str + ' ' + word\n",
    "            else:\n",
    "                cleaned_str += ' '\n",
    "        list_pos += 1\n",
    "    cleaned_str2 = remove_all_space(cleaned_str)\n",
    "    return cleaned_str2\n",
    "\n",
    "remove_features_udf = udf(remove_features, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove noise\n",
    "df_TweetsCleaned = df_TweetLabeled.withColumn(\"cleaned_text\", remove_features_udf(df_TweetLabeled['full_text']))\n",
    "df_TweetsCleaned.select('cleaned_text').show(truncate=50)\n",
    "#df_TweetsCleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizzazione\n",
    "tkn = Tokenizer()\\\n",
    "      .setInputCol(\"cleaned_text\")\\\n",
    "      .setOutputCol(\"words\")\n",
    "\n",
    "# Eliminazione Stopwords\n",
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "stops = StopWordsRemover()\\\n",
    "        .setStopWords(englishStopWords)\\\n",
    "        .setInputCol(\"words\")\\\n",
    "        .setOutputCol(\"words_nsw\")\n",
    "\n",
    "pipeline = Pipeline(stages = [tkn, stops])\n",
    "\n",
    "\n",
    "df_TweetsCleaned = pipeline\\\n",
    "    .fit(df_TweetsCleaned.select(\"full_text\", \"cleaned_text\"))\\\n",
    "    .transform(df_TweetsCleaned.select(\"full_text\", \"cleaned_text\"))\n",
    "\n",
    "df_TweetsCleaned.select(\"full_text\", \"cleaned_text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione Training e Test\n",
    "train, test = df_TweetsCleaned.select(\"words_nsw\", \"label\").randomSplit([0.75,0.25], seed=2020)\n",
    "\n",
    "cv  = CountVectorizer(inputCol='words_nsw', outputCol='tf')\n",
    "idf = IDF().setInputCol('tf').setOutputCol('features')\n",
    "nb  = NaiveBayes()\n",
    "\n",
    "pipeline = Pipeline(stages=[cv, idf, nb])\n",
    "\n",
    "# Dichiarazione della pipeline\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Valutazione del modello con dati di training\n",
    "predictions_train = model.transform(train)\n",
    "\n",
    "# Calcolo dell'accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "eval_train = evaluator.evaluate(predictions_train)\n",
    "\n",
    "# Valutazione del modello con dati di test\n",
    "predictions_test = model.transform(test)\n",
    "\n",
    "# Calcolo dell'accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "eval_test = evaluator.evaluate(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test.select('label').collect()\n",
    "y_pred = predictions_test.select(\"prediction\").collect()\n",
    "confusion_matrix(y_true, y_pred, labels=[\"0\", \"1\", \"2\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
