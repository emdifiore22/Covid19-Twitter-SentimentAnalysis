{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "import string, re, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dati necessari\n",
    "#\n",
    "#\n",
    "ITRetweet = \"./ITRetweet.json\"\n",
    "ITNoRetweet = \"./ITNoRetweet.json\"\n",
    "\n",
    "# Creazione dataFrame\n",
    "df_ITRetweet = spark.read.format(\"json\").option(\"inferSchema\", \"true\").option(\"multiLine\", \"true\").load(ITRetweet)\n",
    "df_ITNoRetweet = spark.read.format(\"json\").option(\"inferSchema\", \"true\").option(\"multiLine\", \"true\").load(ITNoRetweet)\n",
    "\n",
    "# JSON contenente una lista di strutture. Ogni struttura contiene:\n",
    "# - Parola\n",
    "# - positive_Score\n",
    "# - negativeScore\n",
    "sentix = \"./sentix.json\"\n",
    "\n",
    "# Creazione JSON Sentix per l'etichettatura\n",
    "f = open(sentix)\n",
    "sentix_words = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITRetweet\n",
    "\n",
    "df_ITRetweet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITNoRetweet\n",
    "\n",
    "df_ITNoRetweet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIONE DEI RISULTATI\n",
    "\n",
    "df_Tweets = df_ITRetweet\\\n",
    "    .selectExpr(\"id_str\", \"retweeted_status.full_text as full_text\")\\\n",
    "    .union(df_ITNoRetweet.select(\"id_str\", \"full_text\"))\n",
    "\n",
    "\n",
    "df_Tweets = df_Tweets.select(\"full_text\").distinct()\n",
    "df_Tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione funzione per l'eliminazione dei caratteri speciali\n",
    "#\n",
    "#\n",
    "\n",
    "def remove_punct(text):\n",
    "    url_re = re.compile('https?://(www.)?\\w+\\.\\w+(/\\w+)*/?')\n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    mention_re = re.compile('@(\\w+)')\n",
    "    special = re.compile('[\\$#,@&%£!=°§*/;-]')\n",
    "    num_re = re.compile('( \\\\d+)')\n",
    "    text = url_re.sub(\"\", text)\n",
    "    text = punc_re.sub(\"\", text)\n",
    "    text = mention_re.sub(\"\", text)\n",
    "    text = special.sub(\"\", text)\n",
    "    text = num_re.sub(\"\", text)\n",
    "    return text\n",
    "\n",
    "# setup pyspark udf function\n",
    "remove_features_udf = udf(lambda x: remove_punct(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIZIONE FUNZIONE PER L'ETICHETTATURA DEI TWEETS\n",
    "#\n",
    "#\n",
    "\n",
    "emoticonsPositive = ('😇','😊','❤️','😘','💞','💖','🤗','💕','👏','🎉','👍','🔝')\n",
    "emoticonsNegative = ('😂','😡','😠','😭','🤦‍','🤷🏼‍','😞','😱','😓','👎', '🇪🇺')\n",
    "\n",
    "def labeling(tweet):\n",
    "    val = 0\n",
    "    for word in tweet:\n",
    "        if (word in emoticonsPositive):\n",
    "            val = val + 1\n",
    "        elif (word in emoticonsNegative):\n",
    "            val = val - 1\n",
    "        else:\n",
    "            js = list(filter(lambda js: js['lemma']==word, sentix_words))\n",
    "            if(len(js)>0):\n",
    "                val = val + float(js[0]['positive_score'])\n",
    "                val = val - float(js[0]['negativeScore'])\n",
    "                \n",
    "    if(val>0):\n",
    "        # Positivo\n",
    "        return \"2\"\n",
    "    elif(val<0):\n",
    "        # Negativo\n",
    "        return \"1\"\n",
    "    else:\n",
    "        # Neutro\n",
    "        return \"0\"\n",
    "    \n",
    "# setup pyspark udf function\n",
    "label = udf(lambda x: labeling(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminazione caratteri speciali\n",
    "df_noHash = df_Tweets.withColumn('words_filtered',remove_features_udf(\"text\"))\n",
    "\n",
    "# Tokenizzazione\n",
    "tkn = Tokenizer()\\\n",
    "      .setInputCol(\"words_filtered\")\\\n",
    "      .setOutputCol(\"words\")\n",
    "\n",
    "# Eliminazione Stopwords\n",
    "italianStopWords = StopWordsRemover.loadDefaultStopWords(\"italian\")\n",
    "stops = StopWordsRemover()\\\n",
    "        .setStopWords(italianStopWords)\\\n",
    "        .setInputCol(\"words\")\\\n",
    "        .setOutputCol(\"words_nsw\")\n",
    "\n",
    "pipeline = Pipeline(stages = [tkn, stops])\n",
    "\n",
    "df_TweetCleaned = pipeline.fit(df_noHash.select(\"words_filtered\")).transform(df_noHash.select(\"words_filtered\"))\n",
    "\n",
    "df_TweetCleaned.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TweetLabeled = df_TweetCleaned.withColumn(\"label\", label(\"words_nsw\"))\n",
    "\n",
    "df_TweetLabeled.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasformazione label da String a Integer\n",
    "df_TweetLabeled = df_TweetLabeled.withColumn(\"label\", df_TweetLabeled[\"label\"].cast(IntegerType()))\n",
    "\n",
    "# Creazione training set\n",
    "train,test = df_TweetLabeled.randomSplit([0.8,0.2], seed = 2805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.persist()\n",
    "train.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = CountVectorizer(inputCol='words_nsw', outputCol='tf')\n",
    "idf = IDF().setInputCol('tf').setOutputCol('features')\n",
    "nb  = NaiveBayes()\n",
    "\n",
    "pipeline = Pipeline(stages=[cv, idf, nb])\n",
    "\n",
    "# Dichiarazione della pipeline\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Valutazione del modello con dati di training\n",
    "predictions_train = model.transform(train)\n",
    "# Calcolo dell'accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "eval_train = evaluator.evaluate(predictions_train)\n",
    "\n",
    "# Valutazione del modello con dati di test\n",
    "predictions_test = model.transform(test)\n",
    "# Calcolo dell'accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "eval_test = evaluator.evaluate(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (eval_train)\n",
    "print (eval_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
