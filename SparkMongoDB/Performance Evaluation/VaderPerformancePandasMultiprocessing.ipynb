{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo\n",
    "import pandas as pd\n",
    "import string, json, sys, nltk, time, ssl\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from multiprocessing import Pool\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "client = MongoClient(\"mongodb://192.168.1.27:27017/?readPreference=primary&appname=MongoDB%20Compass&ssl=false\")\n",
    "mydb = client[\"TwitterSentimentAnalysis\"]\n",
    "mycol = mydb[\"Covid19\"]\n",
    "\n",
    "\n",
    "noRetweet = mycol.distinct(\"full_text\", {'lang': 'en', 'retweeted_status': None})\n",
    "Retweet = mycol.distinct(\"retweeted_status.full_text\", {'lang': 'en', 'retweeted_status': {'$ne': None}, 'retweeted_status.lang':'en'})\n",
    "\n",
    "tweets = list(dict.fromkeys(noRetweet+Retweet))\n",
    "df = pd.DataFrame(tweets)\n",
    "\n",
    "def vaderSentimentAnalysis(data_str):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(data_str)\n",
    "    ss.pop('compound', None)\n",
    "    maximum = max(ss, key=ss.get)  # Just use 'min' instead of 'max' for minimum.\n",
    "    if maximum == 'neu':\n",
    "        if (ss['neu'] >= 0.6):\n",
    "            return 0\n",
    "        elif (ss['pos'] > ss['neg']):\n",
    "            return 1\n",
    "        elif (ss['neg'] > ss['pos']):\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "    elif maximum == 'pos':\n",
    "        return 1\n",
    "    elif maximum == 'neg':\n",
    "        return 2\n",
    "\n",
    "def apply_vader(df):\n",
    "    df['label'] = df[0].apply(vaderSentimentAnalysis)\n",
    "    return df\n",
    "\n",
    "def parallelize_dataframe(df, func, n_cores=2):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 761 ms, sys: 292 ms, total: 1.05 s\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%time df_labeled = parallelize_dataframe(df, apply_vader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
