{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "import string, re, json\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.mongodb.input.uri\", \"mongodb://192.168.1.27/TwitterSentimentAnalysis.LabeledTweets?retryWrites=true\") \\\n",
    "        .config(\"spark.mongodb.output.uri\", \"mongodb://192.168.1.27/TwitterSentimentAnalysis.LabeledTweets?retryWrites=true\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TweetLabeled = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove whitespace\n",
    "def remove_all_space(astring):\n",
    "  return \" \".join(astring.split())\n",
    "\n",
    "# clean the text \n",
    "def remove_features(data_str):\n",
    "    # compile regex\n",
    "    url_re = re.compile('https?://(www.)?\\w+\\.\\w+(/\\w+)*/?')\n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    num_re = re.compile('(\\\\d+)')\n",
    "    alpha_num_re = re.compile(\"^[a-z0-9_.]+$\")\n",
    "    # convert to lowercase\n",
    "    data_str = data_str.lower()\n",
    "    # remove hyperlinks\n",
    "    data_str = url_re.sub(' ', data_str)\n",
    "    # remove puncuation\n",
    "    data_str = punc_re.sub(' ', data_str)\n",
    "    # remove numeric 'words'\n",
    "    data_str = num_re.sub(' ', data_str)\n",
    "    # remove non a-z 0-9 characters and words shorter than 3 characters\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    for word in data_str.split():\n",
    "        if list_pos == 0:\n",
    "            if alpha_num_re.match(word) and len(word) > 2:\n",
    "                cleaned_str = word\n",
    "            else:\n",
    "                cleaned_str = ' '\n",
    "        else:\n",
    "            if alpha_num_re.match(word) and len(word) > 2:\n",
    "                cleaned_str = cleaned_str + ' ' + word\n",
    "            else:\n",
    "                cleaned_str += ' '\n",
    "        list_pos += 1\n",
    "    cleaned_str2 = remove_all_space(cleaned_str)\n",
    "    return cleaned_str2\n",
    "\n",
    "remove_features_udf = udf(remove_features, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- full_text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- cleaned_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove noise\n",
    "df_TweetsCleaned = df_TweetLabeled.withColumn(\"cleaned_text\", remove_features_udf(df_TweetLabeled['full_text']))\n",
    "#df_TweetsCleaned.select('cleaned_text').show(truncate=50)\n",
    "df_TweetsCleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|           full_text|        cleaned_text|label|               words|           words_nsw|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|\"The United State...|the united states...|    0|[the, united, sta...|[united, states, ...|\n",
      "|Coronavirus &amp;...|coronavirus amp c...|    0|[coronavirus, amp...|[coronavirus, amp...|\n",
      "|Oh to be a 1998 b...|baby first memory...|    0|[baby, first, mem...|[baby, first, mem...|\n",
      "|From uprising to ...|from uprising out...|    0|[from, uprising, ...|[uprising, outbre...|\n",
      "|Another little wa...|another little wa...|    0|[another, little,...|[another, little,...|\n",
      "|â€œOur country is f...|country facing me...|    0|[country, facing,...|[country, facing,...|\n",
      "|ðŸ˜· Dr. Anthony Fa...|anthony fauci the...|    0|[anthony, fauci, ...|[anthony, fauci, ...|\n",
      "|Chinese number is...|chinese number li...|    0|[chinese, number,...|[chinese, number,...|\n",
      "|Union Ministry of...|union ministry he...|    0|[union, ministry,...|[union, ministry,...|\n",
      "|MHC &amp; its par...|mhc amp its partn...|    0|[mhc, amp, its, p...|[mhc, amp, partne...|\n",
      "|As the government...|the government ha...|    0|[the, government,...|[government, decl...|\n",
      "|@kumailn ðŸ“£I will...|kumailn will join...|    0|[kumailn, will, j...|[kumailn, join, s...|\n",
      "|New poll in Italy...|new poll italy hi...|    0|[new, poll, italy...|[new, poll, italy...|\n",
      "|To the medical pr...|the medical profe...|    0|[the, medical, pr...|[medical, profess...|\n",
      "|BREAKING: Gov. JB...|breaking gov prit...|    0|[breaking, gov, p...|[breaking, gov, p...|\n",
      "|Together we can d...|together can defe...|    0|[together, can, d...|[together, defeat...|\n",
      "|In short, the Tru...|short the trump p...|    2|[short, the, trum...|[short, trump, pr...|\n",
      "|BREAKING: \n",
      "\n",
      "â€œAbou...|breaking air and ...|    0|[breaking, air, a...|[breaking, air, a...|\n",
      "|1st 10 minutes of...|minutes democrati...|    0|[minutes, democra...|[minutes, democra...|\n",
      "|Ecuador had the 1...|ecuador had the c...|    0|[ecuador, had, th...|[ecuador, covid, ...|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizzazione\n",
    "tkn = Tokenizer()\\\n",
    "      .setInputCol(\"cleaned_text\")\\\n",
    "      .setOutputCol(\"words\")\n",
    "\n",
    "# Eliminazione Stopwords\n",
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "stops = StopWordsRemover()\\\n",
    "        .setStopWords(englishStopWords)\\\n",
    "        .setInputCol(\"words\")\\\n",
    "        .setOutputCol(\"words_nsw\")\n",
    "\n",
    "pipeline = Pipeline(stages = [tkn, stops])\n",
    "\n",
    "\n",
    "df_TweetsCleanedNSW = pipeline\\\n",
    "    .fit(df_TweetsCleaned.select(\"full_text\", \"cleaned_text\", \"label\"))\\\n",
    "    .transform(df_TweetsCleaned.select(\"full_text\", \"cleaned_text\", \"label\"))\n",
    "\n",
    "# df_TweetsCleaned.select(\"full_text\", \"words_nsw\").show()\n",
    "df_TweetsCleanedNSW.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione Training e Test\n",
    "train, test = df_TweetsCleanedNSW.randomSplit([0.75,0.25], seed=2020)\n",
    "\n",
    "cv  = CountVectorizer(inputCol='words_nsw', outputCol='tf')\n",
    "idf = IDF().setInputCol('tf').setOutputCol('features')\n",
    "nb  = NaiveBayes()\n",
    "\n",
    "pipeline = Pipeline(stages=[cv, idf, nb])\n",
    "\n",
    "# Dichiarazione della pipeline\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Valutazione del modello con dati di training\n",
    "predictions_train = model.transform(train)\n",
    "\n",
    "# Calcolo dell'accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "eval_train = evaluator.evaluate(predictions_train)\n",
    "\n",
    "# Valutazione del modello con dati di test\n",
    "predictions_test = model.transform(test)\n",
    "\n",
    "# Calcolo dell'accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "eval_test = evaluator.evaluate(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_testRDD = predictions_test.select(\"label\",\"prediction\").rdd\n",
    "predictions_testRDD = predictions_testRDD.map(lambda x: (float(x['label']), x['prediction']))\n",
    "# predictions_testRDD.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(predictions_testRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9417.,  200.,  177.],\n",
       "       [ 295.,  178.,   15.],\n",
       "       [ 308.,   20.,  156.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911650544158\n"
     ]
    }
   ],
   "source": [
    "print eval_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.923920474773\n"
     ]
    }
   ],
   "source": [
    "print eval_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.29:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.29:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f820083bcd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
