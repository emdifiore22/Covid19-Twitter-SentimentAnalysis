{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "import string, re, json\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.mongodb.input.uri\", \"mongodb://192.168.1.27/SentimentAnalysisSpark.LabeledTweets?retryWrites=true\") \\\n",
    "        .config(\"spark.mongodb.output.uri\", \"mongodb://192.168.1.27/SentimentAnalysisSpark.LabeledTweets?retryWrites=true\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TweetLabeled = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove whitespace\n",
    "def remove_all_space(astring):\n",
    "  return \" \".join(astring.split())\n",
    "\n",
    "# clean the text \n",
    "def remove_features(data_str):\n",
    "    # compile regex\n",
    "    url_re = re.compile('https?://(www.)?\\w+\\.\\w+(/\\w+)*/?')\n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    num_re = re.compile('(\\\\d+)')\n",
    "    alpha_num_re = re.compile(\"^[a-z0-9_.]+$\")\n",
    "    # convert to lowercase\n",
    "    data_str = data_str.lower()\n",
    "    # remove hyperlinks\n",
    "    data_str = url_re.sub(' ', data_str)\n",
    "    # remove puncuation\n",
    "    data_str = punc_re.sub(' ', data_str)\n",
    "    # remove numeric 'words'\n",
    "    data_str = num_re.sub(' ', data_str)\n",
    "    # remove non a-z 0-9 characters and words shorter than 3 characters\n",
    "    list_pos = 0\n",
    "    cleaned_str = ''\n",
    "    for word in data_str.split():\n",
    "        if list_pos == 0:\n",
    "            if alpha_num_re.match(word) and len(word) > 2:\n",
    "                cleaned_str = word\n",
    "            else:\n",
    "                cleaned_str = ' '\n",
    "        else:\n",
    "            if alpha_num_re.match(word) and len(word) > 2:\n",
    "                cleaned_str = cleaned_str + ' ' + word\n",
    "            else:\n",
    "                cleaned_str += ' '\n",
    "        list_pos += 1\n",
    "    cleaned_str2 = remove_all_space(cleaned_str)\n",
    "    return cleaned_str2\n",
    "\n",
    "remove_features_udf = udf(remove_features, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- full_text: string (nullable = true)\n",
      " |-- id_str: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- cleaned_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove noise\n",
    "df_TweetsCleaned = df_TweetLabeled.withColumn(\"cleaned_text\", remove_features_udf(df_TweetLabeled['full_text']))\n",
    "#df_TweetsCleaned.select('cleaned_text').show(truncate=50)\n",
    "df_TweetsCleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|           full_text|        cleaned_text|label|               words|           words_nsw|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|\"First positive c...|first positive co...|    0|[first, positive,...|[first, positive,...|\n",
      "|\"I feel like I do...|feel like don cou...|    0|[feel, like, don,...|[feel, like, coun...|\n",
      "|\"Most applicants ...|most applicants s...|    0|[most, applicants...|[applicants, say,...|\n",
      "|\"The United State...|the united states...|    0|[the, united, sta...|[united, states, ...|\n",
      "|\"To love purely i...|love purely conse...|    0|[love, purely, co...|[love, purely, co...|\n",
      "|#29. Mrs &amp; Mr...|mrs amp mrs modup...|    0|[mrs, amp, mrs, m...|[mrs, amp, mrs, m...|\n",
      "|#BS \n",
      "#plainandsim...|plainandsimple du...|    0|[plainandsimple, ...|[plainandsimple, ...|\n",
      "|#COVID19 HMG have...|covid hmg have su...|    0|[covid, hmg, have...|[covid, hmg, susp...|\n",
      "|#Coronavirus: #Fl...|coronavirus flori...|    0|[coronavirus, flo...|[coronavirus, flo...|\n",
      "|#Health #KY - Fli...|health flimmaker ...|    0|[health, flimmake...|[health, flimmake...|\n",
      "|#HopkinsEngineer ...|hopkinsengineer p...|    0|[hopkinsengineer,...|[hopkinsengineer,...|\n",
      "|#Italyâ€™s doctors ...|doctors and nurse...|    0|[doctors, and, nu...|[doctors, nurses,...|\n",
      "|#Kerala has #Flat...|kerala has flatte...|    0|[kerala, has, fla...|[kerala, flattent...|\n",
      "|#MoronTrump \n",
      "\n",
      "RT ...|morontrump thehil...|    0|[morontrump, theh...|[morontrump, theh...|\n",
      "|#Qanon if China r...|qanon china relea...|    0|[qanon, china, re...|[qanon, china, re...|\n",
      "|#RT @islaminind: ...|islaminind love c...|    0|[islaminind, love...|[islaminind, love...|\n",
      "|#Waco Mayor Kyle ...|waco mayor kyle d...|    0|[waco, mayor, kyl...|[waco, mayor, kyl...|\n",
      "|.@NYGovCuomo givi...|nygovcuomo giving...|    0|[nygovcuomo, givi...|[nygovcuomo, givi...|\n",
      "|.@NYGovCuomo talk...|nygovcuomo talkin...|    0|[nygovcuomo, talk...|[nygovcuomo, talk...|\n",
      "|1. It took the Ne...|took the new york...|    0|[took, the, new, ...|[took, new, york,...|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizzazione\n",
    "tkn = Tokenizer()\\\n",
    "      .setInputCol(\"cleaned_text\")\\\n",
    "      .setOutputCol(\"words\")\n",
    "\n",
    "# Eliminazione Stopwords\n",
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "stops = StopWordsRemover()\\\n",
    "        .setStopWords(englishStopWords)\\\n",
    "        .setInputCol(\"words\")\\\n",
    "        .setOutputCol(\"words_nsw\")\n",
    "\n",
    "pipeline = Pipeline(stages = [tkn, stops])\n",
    "\n",
    "\n",
    "df_TweetsCleanedNSW = pipeline\\\n",
    "    .fit(df_TweetsCleaned.select(\"full_text\", \"cleaned_text\", \"label\"))\\\n",
    "    .transform(df_TweetsCleaned.select(\"full_text\", \"cleaned_text\", \"label\"))\n",
    "\n",
    "# df_TweetsCleaned.select(\"full_text\", \"words_nsw\").show()\n",
    "df_TweetsCleanedNSW.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione Training e Test\n",
    "train, test = df_TweetsCleanedNSW.randomSplit([0.75,0.25], seed=2020)\n",
    "\n",
    "cv  = CountVectorizer(inputCol='words_nsw', outputCol='tf')\n",
    "idf = IDF().setInputCol('tf').setOutputCol('features')\n",
    "nb  = NaiveBayes()\n",
    "\n",
    "pipeline = Pipeline(stages=[cv, idf, nb])\n",
    "\n",
    "# Dichiarazione della pipeline\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Valutazione del modello con dati di training\n",
    "predictions_train = model.transform(train)\n",
    "\n",
    "# Calcolo dell'accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "eval_train = evaluator.evaluate(predictions_train)\n",
    "\n",
    "# Valutazione del modello con dati di test\n",
    "predictions_test = model.transform(test)\n",
    "\n",
    "# Calcolo dell'accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "eval_test = evaluator.evaluate(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_testRDD = predictions_test.select(\"label\",\"prediction\").rdd\n",
    "predictions_testRDD = predictions_testRDD.map(lambda x: (float(x['label']), x['prediction']))\n",
    "# predictions_testRDD.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(predictions_testRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10842.,   218.,   207.],\n",
       "       [  440.,   210.,    24.],\n",
       "       [  303.,    17.,   148.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.910012574941\n"
     ]
    }
   ],
   "source": [
    "print eval_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922589678802\n"
     ]
    }
   ],
   "source": [
    "print eval_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
